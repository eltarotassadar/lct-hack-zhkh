{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976b9c01",
   "metadata": {},
   "source": [
    "# Подробное руководство по ноутбуку\n",
    "\n",
    "Этот ноутбук показывает полный цикл подготовки признаков и обучения модели для прогноза относительного отклонения потребления горячей воды. Ниже приводится поэтапное описание, чтобы было понятно, что делает каждый блок и в каком порядке лучше их запускать.\n",
    "\n",
    "1. **Установка зависимостей.** В первой ячейке мы ставим `catboost` и `optuna`. Выполните её только один раз в текущей среде — повторный запуск можно пропустить, если библиотеки уже установлены.\n",
    "2. **Импорт библиотек и вспомогательных функций.** Вторая ячейка подключает стандартные пакеты, а также функции из `training_pipeline.data_loader`, которые загружают телеметрию и погодные признаки.\n",
    "3. **Загрузка подготовленных датасетов.** Третья ячейка вызывает `prepare_model_frame()` и возвращает готовый датафрейм, в котором телеметрия объединена с погодой по дате и административному округу.\n",
    "4. **Фиче-инжиниринг и целевая переменная.** Четвёртая ячейка добавляет показатель относительного отклонения `(odpu_hot - itp_cold) / itp_cold`, бинарную метку аномалии (>10%), календарные признаки и скользящие агрегаты, необходимые модели. Перед запуском убедитесь, что предыдущая ячейка выполнена.\n",
    "5. **Разбиение выборки.** Пятая ячейка формирует обучающую и тестовую выборки, выделяет список категориальных признаков и создает объекты `Pool` для CatBoost.\n",
    "6. **Гипертюнинг с Optuna.** Шестая ячейка запускает исследование гиперпараметров. Выполняется относительно долго: можно регулировать количество попыток через параметр `n_trials`.\n",
    "7. **Финальное обучение.** Седьмая ячейка переобучает модель на объединённой обучающей выборке с лучшими найденными параметрами и строит прогноз для тестовой части.\n",
    "8. **Подсчёт метрик и анализ аномалий.** Восьмая ячейка рассчитывает RMSE, MAE, R^2, точность по метке аномалии и формирует сводную таблицу фактов/прогнозов.\n",
    "9. **Сохранение артефактов.** Девятая ячейка записывает модель (`models/catboost_hot_water.cbm`) и файл с метриками (`models/training_metrics.json`), чтобы фронтенд мог их подхватывать.\n",
    "\n",
    "Каждая последующая ячейка предполагает успешное выполнение всех предыдущих. Если вы переоткрыли ноутбук, начните с импорта и повторно прогоните шаги 3–9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270c2ef",
   "metadata": {},
   "source": [
    "### Прогноз отклонений показаний ГВС\n",
    "\n",
    "Ниже представлен обновлённый пайплайн подготовки данных и обучения CatBoost на синтетических таблицах телеметрии и погодных факторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q catboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf0d53",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters injected by papermill\n",
    "telemetry_path = \"data/telemetry.parquet\"\n",
    "weather_path = \"data/weather_features.parquet\"\n",
    "run_id = \"local\"\n",
    "output_model_path = f\"models/catboost_{run_id}.cbm\"\n",
    "metrics_report_path = f\"reports/training_metrics_{run_id}.json\"\n",
    "start_date = None\n",
    "end_date = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from training_pipeline import prepare_model_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем телеметрию и погодные признаки\n",
    "\n",
    "def _load_dataset(path: str):\n",
    "    data_path = Path(path)\n",
    "    if data_path.suffix == \".parquet\":\n",
    "        return pd.read_parquet(data_path)\n",
    "    if data_path.suffix == \".csv\":\n",
    "        return pd.read_csv(data_path)\n",
    "    raise ValueError(f\"Unsupported dataset format: {data_path}\")\n",
    "\n",
    "telemetry_df = _load_dataset(telemetry_path)\n",
    "weather_df = _load_dataset(weather_path)\n",
    "model_df = prepare_model_frame(telemetry=telemetry_df, weather=weather_df)\n",
    "\n",
    "if start_date:\n",
    "    model_df = model_df[model_df[\"date\"] >= pd.to_datetime(start_date)]\n",
    "if end_date:\n",
    "    model_df = model_df[model_df[\"date\"] <= pd.to_datetime(end_date)]\n",
    "\n",
    "model_df = model_df.reset_index(drop=True)\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фиче-инжиниринг: относительное отклонение, лаги, скользящие средние и категориальные признаки\n",
    "model_df = model_df.copy()\n",
    "model_df['target_deviation'] = (model_df['odpu_hot'] - model_df['itp_cold']) / model_df['itp_cold']\n",
    "model_df['anomaly_label'] = (model_df['target_deviation'] > 0.10).astype(int)\n",
    "model_df['month'] = model_df['date'].dt.month\n",
    "model_df['dayofyear'] = model_df['date'].dt.dayofyear\n",
    "model_df['days_from_start'] = (model_df['date'] - model_df['date'].min()).dt.days\n",
    "telemetry_cols = ['odpu_hot', 'itp_hot', 'itp_cold', 'odpu_cold', 'hot_water_consumption', 'cold_water_consumption']\n",
    "for col in telemetry_cols:\n",
    "    model_df[f'{col}_lag1'] = model_df.groupby('mkd_id')[col].shift(1)\n",
    "    model_df[f'{col}_ma3'] = model_df.groupby('mkd_id')[col].transform(\n",
    "        lambda s: s.rolling(window=3, min_periods=1).mean()\n",
    "    )\n",
    "model_df = model_df.dropna().reset_index(drop=True)\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7854a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем выборку на train/test\n",
    "feature_cols = [\n",
    "    'mkd_id', 'mkd_address', 'district', 'itp_id', 'itp_address',\n",
    "    'mkd_lat', 'mkd_lon', 'itp_lat', 'itp_lon',\n",
    "    'odpu_hot', 'itp_hot', 'itp_cold', 'odpu_cold',\n",
    "    'hot_water_consumption', 'cold_water_consumption',\n",
    "    'avg_temp_c', 'min_temp_c', 'max_temp_c',\n",
    "    'heating_degree_days', 'precipitation_mm', 'relative_humidity',\n",
    "    'cloudiness_hours', 'wind_speed_ms', 'wind_load_subzero',\n",
    "    'operational_period',\n",
    "    'month', 'dayofyear', 'days_from_start',\n",
    "] + [col for col in model_df.columns if col.endswith('_lag1') or col.endswith('_ma3')]\n",
    "feature_cols = list(dict.fromkeys(feature_cols))  # удаляем дубликаты\n",
    "target_col = 'target_deviation'\n",
    "categorical_features = ['mkd_id', 'mkd_address', 'district', 'itp_id', 'itp_address', 'operational_period']\n",
    "cat_feature_indices = [feature_cols.index(col) for col in categorical_features]\n",
    "X = model_df[feature_cols]\n",
    "y = model_df[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор гиперпараметров CatBoostRegressor с Optuna\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        'depth': trial.suggest_int('depth', 4, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 5.0),\n",
    "        'border_count': trial.suggest_int('border_count', 64, 254),\n",
    "    }\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.25, random_state=42, shuffle=True\n",
    "    )\n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_indices)\n",
    "    valid_pool = Pool(X_val, y_val, cat_features=cat_feature_indices)\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=300,\n",
    "        loss_function='RMSE',\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        **params,\n",
    "    )\n",
    "    model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "    preds = model.predict(valid_pool)\n",
    "    rmse = mean_squared_error(y_val, preds) ** 0.5\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='catboost-hot-water')\n",
    "study.optimize(objective, n_trials=10, timeout=300)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27852176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем финальную модель на объединённой train-выборке\n",
    "best_params = study.best_params\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_feature_indices)\n",
    "test_pool = Pool(X_test, y_test, cat_features=cat_feature_indices)\n",
    "model = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    loss_function='RMSE',\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    **best_params,\n",
    ")\n",
    "model.fit(train_pool, eval_set=test_pool, use_best_model=True)\n",
    "test_predictions = model.predict(test_pool)\n",
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e28c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем метрики качества и бинарные метки аномалий\n",
    "rmse = mean_squared_error(y_test, test_predictions) ** 0.5\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "true_anomaly = (y_test > 0.10).astype(int)\n",
    "pred_anomaly = (test_predictions > 0.10).astype(int)\n",
    "f1 = f1_score(true_anomaly, pred_anomaly)\n",
    "metrics = {\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'r2': r2,\n",
    "    'f1_anomaly': f1,\n",
    "    'best_params': best_params,\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee639f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем модель и метрики для фронтенда\n",
    "model_path = Path(output_model_path)\n",
    "metrics_path = Path(metrics_report_path)\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.save_model(model_path)\n",
    "with metrics_path.open('w', encoding='utf-8') as fp:\n",
    "    json.dump(metrics, fp, ensure_ascii=False, indent=2)\n",
    "\n",
    "model_path, metrics_path"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
